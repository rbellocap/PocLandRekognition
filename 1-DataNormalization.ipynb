{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation des données\n",
    "\n",
    "Afin de permettre le traitement des données sur le cloud Amazon, il nous faut normaliser nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances\n",
    "%pip install boto3\n",
    "%pip install smart_open\n",
    "%pip install python-dotenv\n",
    "# https://github.com/GeospatialPython/pyshp\n",
    "%pip install pyshp\n",
    "%pip install shapely\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion au bucket S3 Amazon\n",
    "\n",
    "Pour pouvoir travailler avec nos données, nous utilisons un bucket S3 contenant les dataset. Afin de permettre la connexion au service S3, il est nécessaire d'avoir défini un fichier `.env` contenant les variables d'environnements suivantes :\n",
    "\n",
    "```\n",
    "AWS_ACCESS_KEY_ID=xxxxxx\n",
    "AWS_SECRET_ACCESS_KEY=xxxxxx\n",
    "```\n",
    "\n",
    "Ensuite, il suffit d'ouvrir une session à l'aide de la librairie `boto3` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, boto3, dotenv\n",
    "from smart_open import open\n",
    "\n",
    "dotenv.load_dotenv('./.env', override=True)\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id = os.environ['AWS_ACCESS_KEY_ID'],\n",
    "    aws_secret_access_key = os.environ['AWS_SECRET_ACCESS_KEY'],\n",
    ")\n",
    "\n",
    "url = 's3://poc-automatic-land-parcel-recognition/test.txt'\n",
    "\n",
    "with open(url, 'rb', transport_params = {'client': session.client('s3')}) as reader:\n",
    "    for line in reader:\n",
    "        print(line.decode('utf8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fichiers Shapefile\n",
    "\n",
    "L'étape suivante est d'apprendre à traiter les données parcellaires à notre disposition contenues dans un Shapefile.\n",
    "\n",
    "Le shapefile, ou « fichier de formes » est un format de fichier pour les systèmes d'informations géographiques (SIG). Initialement développé par ESRI pour ses logiciels commerciaux, ce format est désormais devenu un standard de facto, dont les spécifications sont ouvertes. Nous allons donc procéder à la lecture d'un exemple de fichier SHP contenant le \"dallage\" global de notre zone à couvrir.\n",
    "\n",
    "Pour cela, nous utilisons la librairie python `pyshp``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[635000.0, 6845000.0, 655000.0, 6875000.0]\n",
      "Record #0: ['./92-2021-0645-6855-LA93-0M20-E080.jp2']\n",
      "[(645000.0, 6855000.0), (650000.0, 6855000.0), (650000.0, 6850000.0), (645000.0, 6850000.0), (645000.0, 6855000.0)]\n",
      "Record #1: ['./92-2021-0640-6870-LA93-0M20-E080.jp2']\n",
      "[(640000.0, 6870000.0), (645000.0, 6870000.0), (645000.0, 6865000.0), (640000.0, 6865000.0), (640000.0, 6870000.0)]\n",
      "Record #2: ['./92-2021-0650-6860-LA93-0M20-E080.jp2']\n",
      "[(650000.0, 6860000.0), (655000.0, 6860000.0), (655000.0, 6855000.0), (650000.0, 6855000.0), (650000.0, 6860000.0)]\n",
      "Record #3: ['./92-2021-0645-6850-LA93-0M20-E080.jp2']\n",
      "[(645000.0, 6850000.0), (650000.0, 6850000.0), (650000.0, 6845000.0), (645000.0, 6845000.0), (645000.0, 6850000.0)]\n",
      "Record #4: ['./92-2021-0645-6860-LA93-0M20-E080.jp2']\n",
      "[(645000.0, 6860000.0), (650000.0, 6860000.0), (650000.0, 6855000.0), (645000.0, 6855000.0), (645000.0, 6860000.0)]\n",
      "Record #5: ['./92-2021-0650-6870-LA93-0M20-E080.jp2']\n",
      "[(650000.0, 6870000.0), (655000.0, 6870000.0), (655000.0, 6865000.0), (650000.0, 6865000.0), (650000.0, 6870000.0)]\n",
      "Record #6: ['./92-2021-0645-6865-LA93-0M20-E080.jp2']\n",
      "[(645000.0, 6865000.0), (650000.0, 6865000.0), (650000.0, 6860000.0), (645000.0, 6860000.0), (645000.0, 6865000.0)]\n",
      "Record #7: ['./92-2021-0635-6870-LA93-0M20-E080.jp2']\n",
      "[(635000.0, 6870000.0), (640000.0, 6870000.0), (640000.0, 6865000.0), (635000.0, 6865000.0), (635000.0, 6870000.0)]\n",
      "Record #8: ['./92-2021-0645-6875-LA93-0M20-E080.jp2']\n",
      "[(645000.0, 6875000.0), (650000.0, 6875000.0), (650000.0, 6870000.0), (645000.0, 6870000.0), (645000.0, 6875000.0)]\n",
      "Record #9: ['./92-2021-0645-6870-LA93-0M20-E080.jp2']\n",
      "[(645000.0, 6870000.0), (650000.0, 6870000.0), (650000.0, 6865000.0), (645000.0, 6865000.0), (645000.0, 6870000.0)]\n",
      "Record #10: ['./92-2021-0640-6860-LA93-0M20-E080.jp2']\n",
      "[(640000.0, 6860000.0), (645000.0, 6860000.0), (645000.0, 6855000.0), (640000.0, 6855000.0), (640000.0, 6860000.0)]\n",
      "Record #11: ['./92-2021-0650-6875-LA93-0M20-E080.jp2']\n",
      "[(650000.0, 6875000.0), (655000.0, 6875000.0), (655000.0, 6870000.0), (650000.0, 6870000.0), (650000.0, 6875000.0)]\n",
      "Record #12: ['./92-2021-0640-6855-LA93-0M20-E080.jp2']\n",
      "[(640000.0, 6855000.0), (645000.0, 6855000.0), (645000.0, 6850000.0), (640000.0, 6850000.0), (640000.0, 6855000.0)]\n",
      "Record #13: ['./92-2021-0635-6865-LA93-0M20-E080.jp2']\n",
      "[(635000.0, 6865000.0), (640000.0, 6865000.0), (640000.0, 6860000.0), (635000.0, 6860000.0), (635000.0, 6865000.0)]\n",
      "Record #14: ['./92-2021-0650-6855-LA93-0M20-E080.jp2']\n",
      "[(650000.0, 6855000.0), (655000.0, 6855000.0), (655000.0, 6850000.0), (650000.0, 6850000.0), (650000.0, 6855000.0)]\n",
      "Record #15: ['./92-2021-0640-6875-LA93-0M20-E080.jp2']\n",
      "[(640000.0, 6875000.0), (645000.0, 6875000.0), (645000.0, 6870000.0), (640000.0, 6870000.0), (640000.0, 6875000.0)]\n",
      "Record #16: ['./92-2021-0640-6865-LA93-0M20-E080.jp2']\n",
      "[(640000.0, 6865000.0), (645000.0, 6865000.0), (645000.0, 6860000.0), (640000.0, 6860000.0), (640000.0, 6865000.0)]\n",
      "Record #17: ['./92-2021-0635-6860-LA93-0M20-E080.jp2']\n",
      "[(635000.0, 6860000.0), (640000.0, 6860000.0), (640000.0, 6855000.0), (635000.0, 6855000.0), (635000.0, 6860000.0)]\n",
      "Record #18: ['./92-2021-0650-6850-LA93-0M20-E080.jp2']\n",
      "[(650000.0, 6850000.0), (655000.0, 6850000.0), (655000.0, 6845000.0), (650000.0, 6845000.0), (650000.0, 6850000.0)]\n"
     ]
    }
   ],
   "source": [
    "import shapefile\n",
    "\n",
    "url = 's3://poc-automatic-land-parcel-recognition/dataset-reference-fr/092/'\n",
    "\n",
    "myshp = open(url + 'dalles.shp', 'rb', transport_params = {'client': session.client('s3')}) # Shapes\n",
    "mydbf = open(url + 'dalles.dbf', 'rb', transport_params = {'client': session.client('s3')}) # Records\n",
    "myprj = open(url + 'dalles.prj', 'rb', transport_params = {'client': session.client('s3')}) # Projection\n",
    "sr = shapefile.Reader(shp=myshp, dbf=mydbf, prj=myprj)\n",
    "\n",
    "print(sr.bbox) # Bounding Box\n",
    "\n",
    "for n in range(0, sr.numRecords):\n",
    "    print(sr.record(n))\n",
    "    print(sr.shape(n).points)\n",
    "    \n",
    "myshp.close()\n",
    "mydbf.close()\n",
    "myprj.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation des données\n",
    "\n",
    "Notre but maintenant est de normaliser notre dataset. En entrée, nous avons les Shapefiles contenant les géométries des parcelles et des fichiers images JPEG 2000 ou GeoTIFF :\n",
    "\n",
    "![SampleDataOrthophoto.png](doc/SampleDataOrthophoto.png)\n",
    "\n",
    "En sortie, on doit produire un fichier JSON dit *manifest* tel que défini dans la [documentation Amazon](https://docs.aws.amazon.com/lookout-for-vision/latest/developer-guide/manifest-files.html) afin d'avoir une données compréhensible par la suite. Ce fichier JSON définit des zones dans l'image, définies par des coordonnées en pixel, qui correspondent aux éléments reconnus dans l'image. Dans notre cas, il s'agira de parcelles.\n",
    "\n",
    "Nous devons donc mettre en place un processus qui :\n",
    "- Va lire les fichiers Shapefile\n",
    "- Va lire les coordonnées des géométries des parcelles (en prenant en compte la projection)\n",
    "- Va trouver l'image correspondante\n",
    "- Va repositionner les points en coordonnées locales en pixel dans l'image\n",
    "- Va générer le [JSON attendu](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-data-output.html#sms-output-video-object-detection)\n",
    "\n",
    "### Lecture du fichier Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image                                     : ./92-2021-0645-6855-LA93-0M20-E080.jp2\n",
      "Format                                    : JPEG 2000\n",
      "Dimensions de l'image                     : 25000px x 25000px\n",
      "Système de coordonnées de référence (SCR) : EPSG:2154 - RGF93 v1 / Lambert-93\n",
      "Coordonnées des bornes de l'image         : POLYGON ((645000 6855000, 650000 6855000, 650000 6850000, 645000 6850000, 645000 6855000))\n",
      "Origine en bas à gauche (en mètre)        : [645000.0, 6850000.0]\n",
      "Dimensions de l'image (en mètre)          : [5000.0, 5000.0]\n",
      "Echelle (en mètres pour 1px)              : [5.0, 5.0]\n",
      " - Parcelle                                        : Shape #0: POLYGON\n",
      "   Coordonnées 1 en mètres                         : (649636.4471738542, 6852112.884597713)\n",
      "   Coordonnées 1 en mètres par rapport à l'origine : [4636.44717385422, 2112.8845977131277]\n",
      "   Coordonnées 1 en pixel par rapport à l'origine  : [23182.2358692711, 10564.422988565639]\n",
      " - Parcelle                                        : Shape #1: POLYGON\n",
      "   Coordonnées 1 en mètres                         : (649695.9767993011, 6852192.592177299)\n",
      "   Coordonnées 1 en mètres par rapport à l'origine : [4695.976799301105, 2192.5921772988513]\n",
      "   Coordonnées 1 en pixel par rapport à l'origine  : [23479.883996505523, 10962.960886494257]\n",
      " - Parcelle                                        : Shape #2: POLYGON\n",
      "   Coordonnées 1 en mètres                         : (649430.076619298, 6852478.383558246)\n",
      "   Coordonnées 1 en mètres par rapport à l'origine : [4430.0766192979645, 2478.383558246307]\n",
      "   Coordonnées 1 en pixel par rapport à l'origine  : [22150.383096489822, 12391.917791231535]\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Polygon, Point, MultiPolygon\n",
    "import imageio\n",
    "\n",
    "url = 's3://poc-automatic-land-parcel-recognition/dataset-reference-fr/092/'\n",
    "limit_dalles = 1\n",
    "limit_parcels = 3\n",
    "\n",
    "# Lecture du fichier contenant les dalles\n",
    "with open(url + 'dalles.shp', 'rb', transport_params = {'client': session.client('s3')}) as dalleshp, open(url + 'dalles.dbf', 'rb', transport_params = {'client': session.client('s3')}) as dalledbf, open(url + 'dalles.prj', 'rb', transport_params = {'client': session.client('s3')}) as dalleprj:\n",
    "    dallerdr = shapefile.Reader(shp=dalleshp, dbf=dalledbf, prj=dalleprj)\n",
    "\n",
    "    # Lecture du fichier contenant les parcelles\n",
    "    with open(url + 'parcelles.shp', 'rb', transport_params = {'client': session.client('s3')}) as parcelleshp, open(url + 'parcelles.dbf', 'rb', transport_params = {'client': session.client('s3')}) as parcelledbf, open(url + 'parcelles.prj', 'rb', transport_params = {'client': session.client('s3')}) as parcelleprj:\n",
    "        parcelrdr = shapefile.Reader(shp=parcelleshp, dbf=parcelledbf, prj=parcelleprj)\n",
    "\n",
    "        # On parcours les dalles\n",
    "        for m in range(0, min(limit_dalles, dallerdr.numRecords)):\n",
    "\n",
    "            # On fabrique un objet polygone avec les points de notre dalle\n",
    "            poly = Polygon(dallerdr.shape(m).points)\n",
    "\n",
    "            # On charge l'image\n",
    "            # img_blue = Image.open(img_path)\n",
    "\n",
    "            # On affiche les informations sur la dalle et l'image correspondante\n",
    "            image = dallerdr.record(m)[0]\n",
    "            height, width = [ 25000, 25000 ]\n",
    "            print(\"Image                                     : \" + image)\n",
    "            print(\"Format                                    : JPEG 2000\")\n",
    "            print(\"Dimensions de l'image                     : \" + str(width) + \"px x \" + str(height) + \"px\")\n",
    "            print(\"Système de coordonnées de référence (SCR) : EPSG:2154 - RGF93 v1 / Lambert-93\")\n",
    "            print(\"Coordonnées des bornes de l'image         : \" + str(poly))\n",
    "            origin = [ poly.boundary.bounds[0], poly.boundary.bounds[1] ]\n",
    "            print(\"Origine en bas à gauche (en mètre)        : \" + str(origin))\n",
    "            bounds = [ poly.boundary.bounds[2] - poly.boundary.bounds[0], poly.boundary.bounds[3] - poly.boundary.bounds[1] ]\n",
    "            print(\"Dimensions de l'image (en mètre)          : \" + str(bounds))\n",
    "\n",
    "            # Le système de coordonnées Lambert 93 est assez simple : les coordonnées sont exprimées en mètres linéaires\n",
    "            # à partir d'un origine en bas à gauche du cadre concerné.\n",
    "            # Voir https://epsg.io/2154\n",
    "            # Pour déterminer les coordonnées X,Y en pixel des parcelles, on applique pour le moment un produit en croix\n",
    "            scale = [ width / (poly.boundary.bounds[2] - poly.boundary.bounds[0]), height / (poly.boundary.bounds[3] - poly.boundary.bounds[1]) ]\n",
    "            print(\"Echelle (en mètres pour 1px)              : \" + str(scale))\n",
    "            \n",
    "            # On parcours les parcelles pour trouver celles incluses dans la dalle\n",
    "            for n in range(0, min(limit_parcels, parcelrdr.numRecords)):\n",
    "                \n",
    "                inside = 0\n",
    "                outside = 0\n",
    "                parcel = parcelrdr.shape(n)\n",
    "                for p in parcel.points:\n",
    "                    if (poly.contains(Point(p))):\n",
    "                        inside += 1\n",
    "                    else:\n",
    "                        outside += 1\n",
    "\n",
    "                # On ignore les parcelles en dehors ou à cheval entre deux dalles\n",
    "                if (inside == 0 or outside > 0):\n",
    "                    continue\n",
    "\n",
    "                print(\" - Parcelle                                        : \" + str(parcel))\n",
    "                print(\"   Coordonnées 1 en mètres                         : \" + str(parcel.points[0]))\n",
    "                coord = [ parcel.points[0][0] - origin[0], parcel.points[0][1] - origin[1] ]\n",
    "                print(\"   Coordonnées 1 en mètres par rapport à l'origine : \" + str(coord))\n",
    "                point = [ coord[0] * scale[0], coord[1] * scale[1] ]\n",
    "                print(\"   Coordonnées 1 en pixel par rapport à l'origine  : \" + str(point))\n",
    "\n",
    "                #for p in parcel.points:\n",
    "                #    coord = [ p[0] - origin[0], p[1] - origin[1] ]\n",
    "                #    point = [ coord[0] * scale[0], coord[1] * scale[1] ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c114a4653cf10b4ae6402cdcbf2cd3fc44926ff120134afa1c1a380eada19be1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
